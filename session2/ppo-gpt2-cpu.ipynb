{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_OFFLINE']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/shareddata/dldata/huggingface-hub-cache/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(model_name,padding_side='left')\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy network\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name,\n",
    "#                                                          load_in_8bit=True,\n",
    "                                                  # torch_dtype=torch.float16,\n",
    "                                                 device_map=\"cpu\"\n",
    "                                                         )\n",
    "model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = model.pretrained_model.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# initialize trainer\n",
    "ppo_config = {\"batch_size\": 2}\n",
    "config = PPOConfig(**ppo_config)\n",
    "ppo_trainer = PPOTrainer(config, model, model_ref, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_trainer.accelerator.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ppo_trainer.current_device='cpu'\n",
    "ppo_trainer.current_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Value head**:A concepts related with actor-critic methods in reinforcement learning.\n",
    "\n",
    "- Definition: In RL, a value head is a component of a neural network that estimates the value of being in a certain state. This value is typically a prediction of the expected cumulative reward from that state onwards, under a certain policy.\n",
    "\n",
    "- Actor-Critic Methods: Actor-critic methods are a class of algorithms in RL that use two models: an actor, which decides which action to take, and a critic, which evaluates the action. The actor is typically a policy network that outputs a probability distribution over actions, while the critic is a value network that estimates the value of the current state or the value of taking an action in the current state.\n",
    "\n",
    "- Role in Language Models: In the context of large language models, a value head could be used to evaluate the potential \"value\" or usefulness of different continuations of a text sequence. For example, it might estimate the expected quality or relevance of a response given the current conversation context.\n",
    "\n",
    "- Application to Language Models: In large language models, an actor-critic approach could be used to both generate text (actor) and evaluate the quality or appropriateness of the generated text (critic). The critic helps in refining the policy of the actor by providing feedback on its performance.\n",
    "\n",
    "- Training and Feedback Loop: The actor is trained to maximize the expected reward, as predicted by the critic. The critic (value head), in turn, is trained to accurately predict the expected reward, minimize the difference between its value predictions and the actual rewards received. This creates a feedback loop where both components improve over time, leading to more effective text generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['How do you like my new hair cut?',\n",
    "           'Do you like Tayler Swift?'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How do you like my new hair cut? Involves you picking up some hooker stuff. The',\n",
       " 'Do you like Tayler Swift?. I would agree. I love her. I mean']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "inputs = tokenizer(prompts, padding=True,\n",
    "                   truncation=True,\n",
    "                   max_length=30, \n",
    "                   return_tensors=\"pt\"\n",
    "                  ).to(device)\n",
    "\n",
    "    # Generate outputs\n",
    "generation_kwargs = {\"min_length\": -1, \n",
    "                     \"top_k\": 0.0, \n",
    "                     \"top_p\": 1.0, \n",
    "                     \"do_sample\": True, \n",
    "                     \"pad_token_id\": tokenizer.eos_token_id\n",
    "                    }\n",
    "\n",
    "outputs = model.generate(**inputs, **generation_kwargs)\n",
    "    \n",
    "    # Decode the outputs\n",
    "responds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "responds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEU', 'score': 0.7851606607437134},\n",
       " {'label': 'POS', 'score': 0.9827784895896912}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results = classifier(responds)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.7851606607437134, 0.9827784895896912]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = []\n",
    "for result in results:\n",
    "    if result['label']=='POS':\n",
    "        reward = result['score']\n",
    "    else: reward = -result['score']\n",
    "    rewards.append(reward)\n",
    "\n",
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # post process for PP\n",
    "        if not getattr(self.model, \"is_sequential_parallel\", False):\n",
    "            self.current_device = self.accelerator.device\n",
    "        else:\n",
    "            if is_xpu_available():\n",
    "                self.current_device = torch.device(\"xpu:0\")\n",
    "            elif is_npu_available():\n",
    "                self.current_device = torch.device(\"npu:0\")\n",
    "            else:\n",
    "                self.current_device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_tensors = tokenizer(prompts, padding=True, truncation=True,\\\n",
    "                   max_length=30, return_tensors=\"pt\")['input_ids'].to(device)\n",
    "input_tensors = []\n",
    "for prompt in prompts:\n",
    "    input_ = tokenizer(prompt, padding=True, truncation=True,\\\n",
    "                   max_length=30, return_tensors=\"pt\")['input_ids']\n",
    "    input_tensors.append(input_.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2437,   466,   345,   588,   616,   649,  4190,  2005,    30,  1400,\n",
       "          1917,  3516,    13, 27522,   340,   373,  2495,  7721, 14930,   276]),\n",
       " tensor([ 5211,   345,   588, 25569,  1754, 15608,    30,  3914,  2488, 16783,\n",
       "         41909,    65,  2792,   534, 10586,  9109,    13,   775,  1549,  1842])]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Get response from gpt2\n",
    "response_tensors = []\n",
    "for input_tensor in input_tensors:\n",
    "    response = ppo_trainer.generate(input_tensor, **generation_kwargs)\n",
    "    response_tensors.append(response.squeeze())\n",
    "response_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-0.7852), tensor(0.9828)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward_tensors = []\n",
    "for reward in rewards:\n",
    "    reward_tensors.append(torch.tensor(reward)) \n",
    "reward_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 6. train model with ppo\n",
    "train_stats = ppo_trainer.step(input_tensors, response_tensors, reward_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective/kl': -14.650461196899414,\n",
       " 'objective/kl_dist': array([  5.824792, -35.125713], dtype=float32),\n",
       " 'objective/logprobs': array([[ -5.5018826 ,  -0.6607917 ,  -3.7719927 ,  -4.227707  ,\n",
       "          -3.4957368 ,  -5.5565023 ,  -4.911383  ,  -0.8654585 ,\n",
       "          -8.497914  ,  -0.7024387 ,  -0.15270673,  -0.16160102,\n",
       "          -0.39465663,  -0.4607508 ,  -1.6175848 ,  -0.6487147 ,\n",
       "          -0.1812358 ,  -7.8150187 ,  -2.1230001 ,  -8.7647    ,\n",
       "          -0.9553639 ,  -8.757273  ,  -1.432316  ,  -0.37418768,\n",
       "          -2.1476197 ,  -9.863121  ,  -0.42350492,  -8.3929205 ],\n",
       "        [ -6.017804  ,  -6.908177  , -14.498096  ,  -5.3655157 ,\n",
       "         -15.539851  , -15.838817  , -12.706747  ,  -4.822152  ,\n",
       "          -9.32054   ,  -2.6144462 ,  -2.236998  ,  -9.134139  ,\n",
       "         -11.119961  ,  -4.3664107 ,  -0.3578121 ,  -8.978776  ,\n",
       "         -13.629381  , -22.985537  , -19.671238  ,  -6.495968  ,\n",
       "         -11.740108  , -18.48944   ,  -8.75942   , -13.091094  ,\n",
       "          -6.5272503 , -10.678213  ,  -7.4915905 ,  -9.7496395 ]],\n",
       "       dtype=float32),\n",
       " 'objective/ref_logprobs': array([[ -5.5044513 ,  -0.6455718 ,  -3.8035622 ,  -4.1656485 ,\n",
       "          -3.5585046 ,  -5.54384   ,  -4.8062987 ,  -0.771494  ,\n",
       "          -8.949823  ,  -0.81857586,  -0.10562231,  -0.1681771 ,\n",
       "          -0.31448507,  -0.3472178 ,  -1.1754786 ,  -0.33232716,\n",
       "          -0.10135111,  -8.222977  ,  -2.3272102 ,  -9.561521  ,\n",
       "          -1.0273836 ,  -9.657317  ,  -1.8577834 ,  -0.5353568 ,\n",
       "          -2.659764  , -10.63252   ,  -1.2847388 ,  -9.611792  ],\n",
       "        [ -6.0754976 ,  -7.6564655 , -14.743109  ,  -5.5019917 ,\n",
       "         -16.385935  , -16.807608  , -11.878522  ,  -6.5588617 ,\n",
       "          -8.73276   ,  -1.3417244 ,  -1.5712131 ,  -4.6672506 ,\n",
       "          -7.8768725 ,  -1.4065437 ,  -0.3266991 ,  -7.855977  ,\n",
       "         -10.707222  , -18.307589  , -15.144579  ,  -5.877687  ,\n",
       "         -11.480638  , -13.010899  , -10.001137  , -14.848102  ,\n",
       "          -7.236474  ,  -8.826523  ,  -6.6012173 ,  -6.491145  ]],\n",
       "       dtype=float32),\n",
       " 'objective/kl_coef': 0.199992,\n",
       " 'objective/entropy': 130.6522979736328,\n",
       " 'ppo/mean_non_score_reward': 0.14649872481822968,\n",
       " 'ppo/mean_scores': 0.09880891442298889,\n",
       " 'ppo/std_scores': 1.2501217126846313,\n",
       " 'tokens/queries_len_mean': 8.0,\n",
       " 'tokens/queries_len_std': 1.4142135381698608,\n",
       " 'tokens/queries_dist': array([9., 7.], dtype=float32),\n",
       " 'tokens/responses_len_mean': 20.0,\n",
       " 'tokens/responses_len_std': 0.0,\n",
       " 'tokens/responses_dist': array([20., 20.], dtype=float32),\n",
       " 'ppo/loss/policy': -0.01081233099102974,\n",
       " 'ppo/loss/value': 9.08910083770752,\n",
       " 'ppo/loss/total': 0.898097813129425,\n",
       " 'ppo/policy/entropy': 3.752452850341797,\n",
       " 'ppo/policy/approxkl': 0.6461008787155151,\n",
       " 'ppo/policy/policykl': -0.20606045424938202,\n",
       " 'ppo/policy/clipfrac': 0.4125000238418579,\n",
       " 'ppo/policy/advantages': array([-3.1114967 , -3.1917334 , -3.276193  , -3.365098  , -3.4586818 ,\n",
       "        -3.557192  , -3.6608863 , -3.7700381 ,  0.16585244,  0.23626961,\n",
       "        -3.0908434 ,  0.5465369 , -1.5457215 , -0.7855483 , -0.6978802 ,\n",
       "        -1.1970729 , -2.3942811 , -0.23842615, -0.29996628, -0.28106305,\n",
       "        -0.5395458 ,  1.7911885 ,  0.5575774 ,  0.34181887,  1.177524  ,\n",
       "         1.4521046 ,  0.66752064,  1.0641514 , -0.6530907 , -0.6039376 ,\n",
       "        -0.5521975 , -0.49773428, -0.44040456, -0.38005748, -0.3165342 ,\n",
       "        -0.24966764,  0.76549435,  0.51225454,  0.73928237,  1.0822328 ,\n",
       "         0.8311267 ,  0.62822986,  0.52634907,  0.7338066 , -1.195954  ,\n",
       "         0.63538903,  0.41653225,  0.22322027, -0.602077  , -0.6686077 ,\n",
       "         0.29830936,  0.05900816,  0.27042517, -0.59369427, -0.62114334,\n",
       "        -0.9703737 , -3.1114967 , -3.1917334 , -3.276193  , -3.365098  ,\n",
       "        -3.4586818 , -3.557192  , -3.6608863 , -3.7700381 ,  0.16585244,\n",
       "         0.23626961, -3.0908434 ,  0.5465369 , -1.5457215 , -0.7855483 ,\n",
       "        -0.6978802 , -1.1970729 , -2.3942811 , -0.23842615, -0.29996628,\n",
       "        -0.28106305, -0.5395458 ,  1.7911885 ,  0.5575774 ,  0.34181887,\n",
       "         1.177524  ,  1.4521046 ,  0.66752064,  1.0641514 , -0.6530907 ,\n",
       "        -0.6039376 , -0.5521975 , -0.49773428, -0.44040456, -0.38005748,\n",
       "        -0.3165342 , -0.24966764,  0.76549435,  0.51225454,  0.73928237,\n",
       "         1.0822328 ,  0.8311267 ,  0.62822986,  0.52634907,  0.7338066 ,\n",
       "        -1.195954  ,  0.63538903,  0.41653225,  0.22322027, -0.602077  ,\n",
       "        -0.6686077 ,  0.29830936,  0.05900816,  0.27042517, -0.59369427,\n",
       "        -0.62114334, -0.9703737 , -3.1114967 , -3.1917334 , -3.276193  ,\n",
       "        -3.365098  , -3.4586818 , -3.557192  , -3.6608863 , -3.7700381 ,\n",
       "         0.16585244,  0.23626961, -3.0908434 ,  0.5465369 , -1.5457215 ,\n",
       "        -0.7855483 , -0.6978802 , -1.1970729 , -2.3942811 , -0.23842615,\n",
       "        -0.29996628, -0.28106305, -0.5395458 ,  1.7911885 ,  0.5575774 ,\n",
       "         0.34181887,  1.177524  ,  1.4521046 ,  0.66752064,  1.0641514 ,\n",
       "        -0.6530907 , -0.6039376 , -0.5521975 , -0.49773428, -0.44040456,\n",
       "        -0.38005748, -0.3165342 , -0.24966764,  0.76549435,  0.51225454,\n",
       "         0.73928237,  1.0822328 ,  0.8311267 ,  0.62822986,  0.52634907,\n",
       "         0.7338066 , -1.195954  ,  0.63538903,  0.41653225,  0.22322027,\n",
       "        -0.602077  , -0.6686077 ,  0.29830936,  0.05900816,  0.27042517,\n",
       "        -0.59369427, -0.62114334, -0.9703737 , -3.1114967 , -3.1917334 ,\n",
       "        -3.276193  , -3.365098  , -3.4586818 , -3.557192  , -3.6608863 ,\n",
       "        -3.7700381 ,  0.16585244,  0.23626961, -3.0908434 ,  0.5465369 ,\n",
       "        -1.5457215 , -0.7855483 , -0.6978802 , -1.1970729 , -2.3942811 ,\n",
       "        -0.23842615, -0.29996628, -0.28106305, -0.5395458 ,  1.7911885 ,\n",
       "         0.5575774 ,  0.34181887,  1.177524  ,  1.4521046 ,  0.66752064,\n",
       "         1.0641514 , -0.6530907 , -0.6039376 , -0.5521975 , -0.49773428,\n",
       "        -0.44040456, -0.38005748, -0.3165342 , -0.24966764,  0.76549435,\n",
       "         0.51225454,  0.73928237,  1.0822328 ,  0.8311267 ,  0.62822986,\n",
       "         0.52634907,  0.7338066 , -1.195954  ,  0.63538903,  0.41653225,\n",
       "         0.22322027, -0.602077  , -0.6686077 ,  0.29830936,  0.05900816,\n",
       "         0.27042517, -0.59369427, -0.62114334, -0.9703737 ], dtype=float32),\n",
       " 'ppo/policy/advantages_mean': 1.4156103134155273e-07,\n",
       " 'ppo/policy/ratio': array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "        1.0249256e+00, 1.1011709e+00, 1.7409219e+00, 1.0120753e+00,\n",
       "        1.4094005e+00, 1.1517912e+00, 1.1023166e+00, 9.9631035e-01,\n",
       "        1.2996482e+00, 9.6069533e-01, 9.8913699e-01, 1.0869545e+00,\n",
       "        1.0843360e+00, 9.3170214e-01, 9.0278178e-01, 1.3818069e+00,\n",
       "        1.0619433e+00, 1.1061625e+00, 8.3791721e-01, 1.1014818e+00,\n",
       "        1.1478108e+00, 1.3165076e+00, 1.1040767e+00, 1.1407492e+00,\n",
       "        1.1587565e+00, 1.2564791e+00, 1.1065528e+00, 1.0937279e+00,\n",
       "        9.9973065e-01, 9.9106926e-01, 1.0177238e+00, 9.8415476e-01,\n",
       "        9.9879909e-01, 9.7178221e-01, 9.6530497e-01, 9.9096072e-01,\n",
       "        1.0507601e+00, 1.0198162e+00, 9.7959495e-01, 9.9615413e-01,\n",
       "        9.6414059e-01, 9.4229567e-01, 8.2759064e-01, 8.4276301e-01,\n",
       "        9.6347028e-01, 1.0406955e+00, 1.0295118e+00, 1.0723658e+00,\n",
       "        1.0040529e+00, 1.2036551e+00, 1.0687748e+00, 1.0263189e+00,\n",
       "        1.0744325e+00, 1.2617674e+00, 1.0827912e+00, 1.3200252e+00,\n",
       "        1.0675831e+00, 1.7340652e+00, 1.5956625e+00, 1.0270616e+00,\n",
       "        2.3084812e+00, 9.8718721e-01, 1.2728138e+00, 9.9850386e-01,\n",
       "        1.7470807e+00, 9.3738115e-01, 1.2158053e+00, 1.5619168e+01,\n",
       "        3.4716265e+00, 1.6674227e+00, 8.9522022e-01, 1.6050670e+00,\n",
       "        9.9321294e-01, 4.1269617e+00, 9.4725966e-01, 1.1165081e+00,\n",
       "        5.2645010e-01, 4.9417740e-01, 1.0913846e+00, 1.1627095e+00,\n",
       "        1.7912307e+00, 7.7219200e-01, 8.6151886e-01, 4.5605496e-01,\n",
       "        9.9825728e-01, 9.8195624e-01, 1.0251651e+00, 9.5848960e-01,\n",
       "        9.8574877e-01, 9.4538069e-01, 9.1251928e-01, 9.9493390e-01,\n",
       "        1.1070764e+00, 1.0379833e+00, 9.5642591e-01, 9.9027401e-01,\n",
       "        9.2564178e-01, 8.7359840e-01, 6.6058320e-01, 6.5613121e-01,\n",
       "        9.2307651e-01, 1.0440233e+00, 9.9213183e-01, 1.0917823e+00,\n",
       "        1.0055883e+00, 1.3706678e+00, 1.1423949e+00, 1.0476267e+00,\n",
       "        1.1722873e+00, 1.4813600e+00, 1.1611311e+00, 1.5857472e+00,\n",
       "        1.0846525e+00, 2.2793584e+00, 9.1732085e-01, 1.0530423e+00,\n",
       "        2.1609912e+00, 9.8066103e-01, 1.0625856e+00, 1.0032434e+00,\n",
       "        2.2718160e+00, 1.0077211e+00, 1.2799844e+00, 1.7762526e+02,\n",
       "        1.7508327e+01, 2.0960264e+00, 9.7981334e-01, 1.4436727e+00,\n",
       "        5.5630839e-01, 7.9782972e+00, 2.5733967e+00, 1.7529069e+00,\n",
       "        2.2322147e-01, 2.7136597e-01, 1.3313607e+00, 1.3157984e+00,\n",
       "        2.6514564e+00, 4.3817407e-01, 5.2867091e-01, 2.0451511e-01,\n",
       "        9.9790508e-01, 9.7029483e-01, 1.0277534e+00, 9.3048251e-01,\n",
       "        9.6696639e-01, 9.2760694e-01, 8.7272429e-01, 9.9775636e-01,\n",
       "        1.1797868e+00, 1.0564629e+00, 9.2958248e-01, 9.8406184e-01,\n",
       "        8.8555634e-01, 8.0404329e-01, 5.4934561e-01, 5.1758140e-01,\n",
       "        8.7976003e-01, 1.0269020e+00, 9.2335546e-01, 1.0695345e+00,\n",
       "        1.0039281e+00, 1.5134323e+00, 1.2258772e+00, 1.0662444e+00,\n",
       "        1.3037326e+00, 1.6615732e+00, 1.2301497e+00, 1.8207420e+00,\n",
       "        1.1009871e+00, 2.6505704e+00, 5.7662517e-01, 1.0239286e+00,\n",
       "        1.9648352e+00, 1.3564612e+00, 6.1727953e-01, 9.7291070e-01,\n",
       "        2.9579897e+00, 1.1054058e+00, 1.3408026e+00, 2.8450469e+03,\n",
       "        7.2986340e+02, 2.5677509e+00, 1.0274408e+00, 1.3360629e+00,\n",
       "        3.3649841e-01, 1.2457153e+01, 5.5521317e+00, 2.6039085e+00,\n",
       "        1.0674929e-01, 1.6890973e-01, 1.5718786e+00, 1.3740091e+00,\n",
       "        3.6915238e+00, 2.8719389e-01, 3.5333303e-01, 1.0474969e-01],\n",
       "       dtype=float32),\n",
       " 'ppo/returns/mean': -0.7607596516609192,\n",
       " 'ppo/returns/var': 1.5254364013671875,\n",
       " 'ppo/val/vpred': -4.44730806350708,\n",
       " 'ppo/val/error': 20.261329650878906,\n",
       " 'ppo/val/clipfrac': 0.574999988079071,\n",
       " 'ppo/val/mean': -4.889693737030029,\n",
       " 'ppo/val/var': 4.359621047973633,\n",
       " 'ppo/val/var_explained': -12.282317161560059,\n",
       " 'ppo/learning_rate': 1e-05,\n",
       " 'time/ppo/forward_pass': 3.0119471549987793,\n",
       " 'time/ppo/compute_rewards': 0.14576315879821777,\n",
       " 'time/ppo/compute_advantages': 0.04506683349609375,\n",
       " 'time/ppo/optimize_step': 10.06976842880249,\n",
       " 'time/ppo/calc_stats': 0.03629112243652344,\n",
       " 'time/ppo/total': 13.375245094299316}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel2",
   "language": "python",
   "name": "kernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_OFFLINE']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/shareddata/dldata/huggingface-hub-cache/hub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOConfig, PPOTrainer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate responds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "# model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name,\n",
    "                                                         # load_in_8bit=True,\n",
    "                                                  # torch_dtype=torch.float16,\n",
    "                                                 device_map=\"auto\")\n",
    "# model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(model_name,torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = model.pretrained_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the sentences\n",
    "prompts_list = []\n",
    "\n",
    "# Open the text file\n",
    "with open('prompts.txt', 'r') as file:\n",
    "    # Read each line in the file\n",
    "    for line in file:\n",
    "        # Add the line (sentence) to the list\n",
    "        prompts_list.append(line.strip())\n",
    "\n",
    "# Now 'sentences' contains all the sentences from the file\n",
    "print( prompts_list[:10])\n",
    "print(len(prompts_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "prompt_batches = [prompts_list[i:i + batch_size] for i in range(0, len(prompts_list), batch_size)]\n",
    "# print(prompt_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_responds = []\n",
    "for batch in prompt_batches:\n",
    "\n",
    "    # Tokenize the batch\n",
    "    inputs = tokenizer(batch, padding=True, truncation=True,max_length=30, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate outputs\n",
    "    outputs = model.generate(**inputs)\n",
    "    \n",
    "    # Decode the outputs\n",
    "    responds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "    # Collect all generated texts\n",
    "    all_responds.extend(responds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_responds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# data_dict = {\n",
    "#     \"prompt\": prompts_list,  # List of all prompts\n",
    "#     \"response\": all_responds  # Corresponding generated texts\n",
    "# }\n",
    "\n",
    "# dataset = Dataset.from_dict(data_dict)\n",
    "# dataset.save_to_disk(\"./completion_llama2_7b_chat\")\n",
    "\n",
    "# For native format\n",
    "loaded_dataset = Dataset.load_from_disk(\"./completion_llama2_7b_chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\",                      model=\"facebook/bart-large-mnli\",  batch_size=2\n",
    "#                       device=0 #use 1 gpu\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForSequenceClassification(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): BartClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_to_classify = loaded_dataset['response']\n",
    "candidate_labels = ['positive', 'negative']\n",
    "results = classifier(sequences_to_classify, candidate_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'As the sun dipped below the horizon, she whispered Sheila\\'s name into the darkness.\\n\\nThe wind rustled through the trees, carrying the sound of her voice to the ears of the sleeping girl. She stirred, her eyelids flickering open, and she saw her mother standing over her, her face bathed in the soft, golden light of the setting sun.\\n\\n\"Mother?\" Sheila said, her voice barely above a whisper.\\n\\n\"Shh, my child,\" her mother replied, her voice low and soothing. \"I\\'m here, and I\\'ll always be here for you.\"\\n\\nSheila smiled, feeling a sense of peace wash over her. She knew that her mother would always be there to protect her, to guide her, and to love her. And as the stars began to twinkle in the sky, she drifted off to sleep, surrounded by the warmth and love of her mother\\'s embrace.',\n",
       "  'labels': ['positive', 'negative'],\n",
       "  'scores': [0.8609572649002075, 0.1390426903963089]},\n",
       " {'sequence': 'In the heart of the bustling city, the old clock tower stood tall and proud, a symbol of tradition and heritage. It had been there for as long as anyone could remember, keeping time for the people of the city with its steady tick-tock.\\n\\nBut as the years passed, the clock tower began to show its age. The once-bright paint had faded to a dull gray, and the hands of the clock had become worn and weathered. The city\\'s residents had grown accustomed to the tower\\'s dignified presence, but they couldn\\'t help feeling a sense of unease as the years went by without any noticeable repairs or improvements.\\n\\nOne day, a group of young activists decided to take matters into their own hands. They organized a protest in front of the clock tower, demanding that the city government do something to restore the landmark to its former glory.\\n\\n\"It\\'s time for change!\" they chanted, waving signs and banners. \"We deserve a clock tower we can be proud of!\"\\n\\nThe city officials were caught off guard by the sudden outcry, but they knew they couldn\\'t ignore the public\\'s demands forever. They agreed to allocate funds for a thorough restoration of the clock tower, and work began on the project.\\n\\nAs the workers scaffolded the tower and began the long process of repairing and repainting it, the city\\'s residents watched with a mix of excitement and trepidation. What would the new and improved clock tower look like? Would it still be the same beloved landmark they had grown up with?\\n\\nWhen the restoration was complete, the city gathered to see the results. The clock tower stood tall and proud once again, its fresh coat of paint gleaming in the sunlight. The hands of the clock were now made of shining brass, and the face of the clock was adorned with intricate carvings.\\n\\nThe people of the city cheered and applauded as they gazed upon their renewed landmark. It was as if the clock tower had been reborn, ready to continue keeping time for generations to come.\\n\\nThe young activists who had led the protest were overjoyed at the outcome. They had fought for something they believed in, and their efforts had paid off.\\n\\nAs the sun set on the newly restored clock tower, the city\\'s residents looked on with a sense of pride and gratitude. They knew that their beloved landmark was here to stay, and that it would continue to be a symbol of tradition and heritage for years to come.',\n",
       "  'labels': ['positive', 'negative'],\n",
       "  'scores': [0.9228182435035706, 0.07718174904584885]}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8609572649002075,\n",
       " 0.9228182435035706,\n",
       " 0.5317773222923279,\n",
       " 0.8464366793632507,\n",
       " 0.8121617436408997,\n",
       " 0.8203584551811218,\n",
       " 0.930128812789917,\n",
       " 0.8936605453491211,\n",
       " 0.6091751456260681,\n",
       " 0.7915117740631104,\n",
       " 0.8447045683860779,\n",
       " 0.5947400331497192,\n",
       " 0.9344221949577332,\n",
       " 0.7813522219657898,\n",
       " 0.6773231625556946,\n",
       " 0.8200052380561829,\n",
       " 0.5995565056800842,\n",
       " 0.7572034001350403,\n",
       " 0.9054780006408691,\n",
       " 0.657005250453949,\n",
       " 0.6353934407234192,\n",
       " 0.8420088291168213,\n",
       " 0.9306694269180298,\n",
       " 0.5814589262008667,\n",
       " 0.5401087403297424,\n",
       " 0.8723199367523193,\n",
       " 0.7645217180252075,\n",
       " 0.8475704789161682,\n",
       " 0.952715277671814,\n",
       " 0.6110256314277649,\n",
       " 0.5725849866867065,\n",
       " 0.9297687411308289,\n",
       " 0.7758700847625732,\n",
       " 0.8660721182823181,\n",
       " 0.7207596898078918,\n",
       " 0.6905559301376343,\n",
       " 0.7340685725212097,\n",
       " 0.7655181884765625,\n",
       " 0.8030501008033752,\n",
       " 0.8590245246887207,\n",
       " 0.6460024118423462,\n",
       " 0.5988187789916992,\n",
       " 0.9237439632415771,\n",
       " 0.6969642043113708,\n",
       " 0.8532393574714661,\n",
       " 0.9171209335327148,\n",
       " 0.799035906791687,\n",
       " 0.7769084572792053,\n",
       " 0.9089163541793823,\n",
       " 0.9842427372932434,\n",
       " 0.5340001583099365,\n",
       " 0.7298489809036255,\n",
       " 0.7746542692184448,\n",
       " 0.9463294148445129,\n",
       " 0.5893089771270752,\n",
       " 0.7731505632400513,\n",
       " 0.5048671960830688,\n",
       " 0.6047829389572144,\n",
       " 0.8994974493980408,\n",
       " 0.9715494513511658,\n",
       " 0.568687915802002,\n",
       " 0.832185685634613,\n",
       " 0.7315090298652649,\n",
       " 0.6934846043586731,\n",
       " 0.7602920532226562,\n",
       " 0.9353978633880615,\n",
       " 0.741733968257904,\n",
       " 0.8530656695365906,\n",
       " 0.5964614748954773,\n",
       " 0.7356870770454407,\n",
       " 0.7868953347206116,\n",
       " 0.9083028435707092,\n",
       " 0.8254716992378235,\n",
       " 0.9498590230941772,\n",
       " 0.5205588340759277,\n",
       " 0.5499250888824463,\n",
       " 0.8394215106964111,\n",
       " 0.8914849162101746,\n",
       " 0.9186461567878723,\n",
       " 0.739498496055603]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = [result['scores'][0] for result in results]\n",
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel2",
   "language": "python",
   "name": "kernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
